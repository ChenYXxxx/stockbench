from __future__ import annotations

from pathlib import Path
from typing import List, Optional
import re
import os

import typer
import yaml

from stockbench.backtest.pipeline import run_backtest
from stockbench.backtest.strategies.llm_decision import Strategy as LlmDecision
from stockbench.utils.logging_setup import setup_json_logging, Metrics
from stockbench.backtest.reports import _default_run_id
from stockbench.core.data_hub import set_data_mode

app = typer.Typer(add_completion=False)


@app.command()
def main(
    cfg: Path = typer.Option(..., exists=True, readable=True, help="Configuration file path"),
    start: str = typer.Option("2025-03-01", help="Start date"),
    end: str = typer.Option("2025-07-31", help="End date"),
    symbols: str = typer.Option("", "--symbols", "-s", help="Backtest symbols (comma or space separated)"),
    strategy: str = typer.Option("llm_decision", help="Strategy: llm_decision"),
    run_id: str = typer.Option(None, help="Output run_id (auto-generated by default)"),
    # Risk control and LLM control
    max_positions: int = typer.Option(None, help="Maximum number of positions (use config if empty)"),
    cooldown_days: int = typer.Option(None, help="Cooldown days after clearing positions (use config if empty)"),
    min_holding_days: int = typer.Option(None, help="Minimum holding days (use config if empty)"),
    # Agent mode selection
    agent_mode: str = typer.Option(None, help="Agent mode: dual|single (use config if empty)"),
    # LLM profile switching
    llm_profile: str = typer.Option(None, help="Select LLM profile to override llm section: openai|gpt-oss-20b (corresponds to config.llm_profiles)"),
    # News sentiment aggregation
    news_agg: str = typer.Option(None, help="News sentiment aggregation: mean|median|trimmed_mean (use config if empty)"),
    news_trim_alpha: float = typer.Option(None, help="News sentiment trimmed mean parameter alpha (0.0~0.49, use config if empty)"),
    # Backtest summary (natural language)
    summary_llm: Optional[bool] = typer.Option(None, help="Whether to call real LLM to generate natural language summary after backtest (use config if empty)"),
    # Benchmark (M3 CLI): choose one (symbol or basket) or new per-symbol buy&hold
    benchmark_symbol: str = typer.Option(None, help="Benchmark single symbol, e.g., SPY"),
    benchmark_basket: str = typer.Option(None, help="Benchmark basket, JSON or comma separated (supports SPY:0.5,QQQ:0.5 or ['SPY','QQQ'])"),
    benchmark_field: str = typer.Option(None, help="Benchmark price field: adjusted_close|close"),
    benchmark_rebalance: str = typer.Option(None, help="Basket rebalancing: daily|monthly|none"),
    benchmark_reindex: str = typer.Option(None, help="Alignment: inner_join|business"),
    benchmark_fill: str = typer.Option(None, help="Filling: ffill|none (only effective for business)"),
    benchmark_fill_limit: int = typer.Option(None, help="Fill limit days, recommend ≥3"),
    # currency removed (no consumer)
    # Per-symbol buy&hold options
    benchmark_type: str = typer.Option(None, help="Benchmark type: symbol|basket|per_symbol_buy_and_hold"),
    benchmark_total_cash: float = typer.Option(None, help="Per-symbol BH: override total cash"),
    benchmark_trade_price_field: str = typer.Option(None, help="Per-symbol BH: trade price field on first day: open|adjusted_close|close"),
    benchmark_daily_metrics: str = typer.Option(None, help="Per-symbol BH: daily metrics list, e.g., cum_return,max_drawdown,sortino"),
    benchmark_sortino_mode: str = typer.Option(None, help="Per-symbol BH: sortino mode: rolling|to_date"),
    benchmark_sortino_window: int = typer.Option(None, help="Per-symbol BH: sortino rolling window (trading days)"),
    benchmark_save_format: str = typer.Option(None, help="Per-symbol BH: outputs: comma separated, e.g., text,image"),
    # Data mode
    data_mode: str = typer.Option(None, help="Data mode: auto|offline_only (aliases: offline|cache|cache_only)"),
    offline: bool = typer.Option(False, help="Shortcut for --data-mode offline_only"),
):
    # Read configuration first, then initialize logging based on it (levels & bridges)
    with cfg.open("r", encoding="utf-8") as f:
        config = yaml.safe_load(f)

    setup_json_logging(config)
    # Apply data mode (CLI overrides config and env)
    try:
        if offline:
            set_data_mode("offline_only")
        elif data_mode:
            set_data_mode(str(data_mode))
        else:
            # Also respect config.data.mode if provided
            dm = ((config.get("data", {}) or {}).get("mode", None))
            if dm:
                set_data_mode(str(dm))
    except Exception:
        pass
    m = Metrics()
    m.incr("run_backtest.start", 1)

    # Parse symbols
    sym_list: List[str] = []
    if symbols:
        sym_list = [s for s in re.split(r"[\s,]+", symbols.strip()) if s]
    if not sym_list:
        sym_list = list(config.get("symbols_universe", []))

    # Determine run_id before running and inject into environment for LLM cache indexing by run_id
    effective_run_id = run_id or _default_run_id()
    try:
        os.environ["TA_RUN_ID"] = effective_run_id
    except Exception:
        pass
    
    # LLM profile override - use openai profile by default
    profiles = (config.get("llm_profiles", {}) or {})
    if llm_profile:
        prof = profiles.get(str(llm_profile).lower())
    else:
        # Use openai profile by default
        prof = profiles.get("openai")
    
    if isinstance(prof, dict) and prof:
        config["llm"] = {**(config.get("llm", {}) or {}), **prof}

    # Override configuration (risk control and LLM)
    if max_positions is not None:
        config.setdefault("risk", {})["max_positions"] = int(max_positions)
    if cooldown_days is not None:
        config.setdefault("risk", {})["cooldown_days"] = int(cooldown_days)
    if min_holding_days is not None:
        config.setdefault("risk", {})["min_holding_days"] = int(min_holding_days)
    # Agent mode override
    if agent_mode is not None:
        config.setdefault("agents", {})["mode"] = str(agent_mode)
    # Backtest summary
    if summary_llm is not None:
        config.setdefault("backtest", {})["summary_llm"] = bool(summary_llm)

    # Execution override - only day timespan supported
    config.setdefault("backtest", {})["timespan"] = "day"

    # News aggregation/ablation
    if news_agg:
        config.setdefault("news", {})["agg"] = str(news_agg)
    if news_trim_alpha is not None:
        config.setdefault("news", {})["trim_alpha"] = float(news_trim_alpha)


    # Benchmark CLI override (optional)
    try:
        # Backward compatibility: unify writes to backtest.benchmark
        bench_cfg = config.setdefault("backtest", {}).setdefault("benchmark", {})
        if benchmark_type:
            bench_cfg["type"] = benchmark_type
        if benchmark_symbol:
            bench_cfg["symbol"] = benchmark_symbol
        if benchmark_basket:
            bench_cfg["basket"] = benchmark_basket
        if benchmark_field:
            bench_cfg["field"] = benchmark_field
        if benchmark_rebalance:
            bench_cfg["rebalance"] = benchmark_rebalance
        if benchmark_reindex:
            bench_cfg["reindex"] = benchmark_reindex
        if benchmark_fill is not None:
            bench_cfg["fill"] = benchmark_fill
        if benchmark_fill_limit is not None:
            bench_cfg["fill_limit"] = int(benchmark_fill_limit)
        # currency removed (no consumer)
        # Force day-only timespan
        bench_cfg["timespan"] = "day"
        # per-symbol buy&hold specific
        if benchmark_total_cash is not None:
            bench_cfg["total_cash"] = float(benchmark_total_cash)
        if benchmark_trade_price_field:
            bench_cfg["trade_price_field"] = str(benchmark_trade_price_field)
        # daily metrics
        if benchmark_daily_metrics:
            items = [s.strip() for s in str(benchmark_daily_metrics).split(",") if s.strip()]
            dm = bench_cfg.setdefault("daily_metrics", {})
            dm["enabled"] = True
            dm["metrics"] = items
        if benchmark_sortino_mode or benchmark_sortino_window is not None:
            dm = bench_cfg.setdefault("daily_metrics", {})
            sortino = dm.setdefault("sortino", {})
            if benchmark_sortino_mode:
                sortino["mode"] = str(benchmark_sortino_mode)
            if benchmark_sortino_window is not None:
                sortino["window"] = int(benchmark_sortino_window)
        if benchmark_save_format:
            dm = bench_cfg.setdefault("daily_metrics", {})
            fmts = [s.strip() for s in str(benchmark_save_format).split(",") if s.strip()]
            dm["save_format"] = fmts
    except Exception:
        pass

    # Select strategy
    strat_name = strategy.strip().lower()
    if strat_name == "llm_decision":
        strat = LlmDecision(config)
    else:
        # Default to LLM decision strategy since rule_baseline was removed
        strat = LlmDecision(config)

    res0 = run_backtest(config, strat, start, end, sym_list, run_id=effective_run_id, timespan="day")

    # Print output directory for locating artifacts
    try:
        out_dir = res0.get("output_dir") if isinstance(res0, dict) else None
        if out_dir:
            typer.echo(f"Output directory: {out_dir}")
    except Exception:
        pass

    return res0


if __name__ == "__main__":  # pragma: no cover
    app() 